{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ce1589-b0b5-4440-83fc-d040bf7a0981",
   "metadata": {},
   "source": [
    "# In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b809dc84-fb2b-4321-881f-b8f1e6494280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60ccada-1410-4419-b914-8d186cca4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87a7dab-422f-497d-ade1-2326c6dcbaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_fast.PreTrainedTokenizerFast"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7830275-f25a-4194-ae10-c74d8c9063ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d2110226c8441cbd09a0790357ff17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e244f763-de31-48b4-90d8-efc1ee9487f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully \n",
    "as possible, while being safe. Your answers should not include any harmful, \n",
    "unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure \n",
    "that your responses are socially unbiased and positive in nature. If a question \n",
    "does not make any sense, or is not factually coherent, explain why instead of \n",
    "answering something not correct. If you don’t know the answer to a question, \n",
    "please don’t share false information.\n",
    "\n",
    "\n",
    "{CONTEXT}\n",
    "\n",
    "Question: {QUESTION}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960db73a-c881-41f5-b0e3-f5c73cb0530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(CONTEXT=\"\", QUESTION=\"How many years Albert Einstein has lived in Germany?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d54ba0-6829-4448-99b4-aed091850b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=1.0,\n",
    "    max_length=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc76fba9-acbe-4ea3-b1ca-1191a873004b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully \\nas possible, while being safe. Your answers should not include any harmful, \\nunethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure \\nthat your responses are socially unbiased and positive in nature. If a question \\ndoes not make any sense, or is not factually coherent, explain why instead of \\nanswering something not correct. If you don’t know the answer to a question, \\nplease don’t share false information.\\n\\n\\n\\n\\nQuestion: How many years Albert Einstein has lived in Germany?\\nAnswer: \\n\\nQuestion: How many years Albert Einstein has lived in Germany?\\nAnswer: \\n\\nQuestion: What's Einstein's IQ?\\nAnswer: \\n\\nQuestion: When did Einstein discover general relativity?\\nAnswer: \\n\\nQuestion: Where did Einstein discover the formula?\\nAnswer: \\n\\nQuestion: What does general relativity say?\\nAnswer: \\n\\nQuestion: Where did Einstein discover general relativity?\\nAnswer\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc95036-04ab-4639-a973-3750c15a9050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>What is the sentiment of this?\\nThis movie is great.\\nA: This movie is great.\\nB: Great movie.\\nC: It's a great movie.\\nD: This movie rocks!\\nE: This is an epic movie.\\nF: This is a good movie.\\nG: This is a wonderful movie.\\nI would like to go see this movie tonight.\\nA: This movie is great.\\nB: Great movie.\\nC: It's a great movie.\\nD: This movie rocks!\\nE: This is an epic movie.\\nF: This is a good movie.\\nG: This is a wonderful movie.\\nI would like to go see this movie tonight.\\nD and G are good answers.\\nThis movie is epic.\\nThis is an epic movie.<|end_of_text|>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"What is the sentiment of this?\n",
    "This movie is great.\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=1.0,\n",
    "    max_length=200\n",
    ")\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c82cfb-5549-48fd-ad74-af9d73620347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Context: Suppose you are a history teacher with more than 30 years of teaching experience.  \n",
    "Instructions: Write a multiple-choice question for a history course.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please classify the news snippets and output as JSON:\n",
    "\n",
    "Circulation revenue has increased by 5% in Finland.\n",
    "---- Positive\n",
    "Panostaja did not disclose the purchase price.\n",
    "---- Neutral\n",
    "Paying off the national debt will be extremely painful.\n",
    "---- Negative\n",
    "The company anticipated its operating profit to improve.\n",
    "---- \"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=1.0,\n",
    "    max_length=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031de7ee-3fdd-46be-aff2-15e951b8c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>\\nPlease classify the news snippets and output as JSON:\\n\\nCirculation revenue has increased by 5% in Finland.\\n---- Positive\\nPanostaja did not disclose the purchase price.\\n---- Neutral\\nPaying off the national debt will be extremely painful.\\n---- Negative\\nThe company anticipated its operating profit to improve.\\n----  Neutral\\nPanostaja, the largest private investment company in Finland, bought 100% of the shares in Tunturi from the British company, Lystec.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86ee8229-fe0e-4549-9373-ef4ae51c3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Gu Ailing won the first crown of the New Year of the Rabbit. Scoring break advantage.  \n",
    "---- sports   \n",
    "Data released by the National Health Insurance Bureau showed that from January to March 2023, the total income of the basic medical insurance fund (including maternity insurance) was 910.48 billion yuan, an increase of 9.5% year-on-year.  \n",
    "---- medical   \n",
    "Berkshire Hathaway reduced its stake in BYD shares from 10.05% to 9.87%. The HKEx Disclosure Ease requires disclosure when a major shareholder increases or decreases its shareholding only if it crosses a certain round number percentage.  \n",
    "---- Finance  \n",
    "Edge computing products have served customers in industries such as online education, video, gaming, and connected cars.\n",
    "----  \"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=1.0,\n",
    "    max_length=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a57bfb3a-2837-44d4-897a-a8c766492492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>\\nGu Ailing won the first crown of the New Year of the Rabbit. Scoring break advantage.  \\n---- sports   \\nData released by the National Health Insurance Bureau showed that from January to March 2023, the total income of the basic medical insurance fund (including maternity insurance) was 910.48 billion yuan, an increase of 9.5% year-on-year.  \\n---- medical   \\nBerkshire Hathaway reduced its stake in BYD shares from 10.05% to 9.87%. The HKEx Disclosure Ease requires disclosure when a major shareholder increases or decreases its shareholding only if it crosses a certain round number percentage.  \\n---- Finance  \\nEdge computing products have served customers in industries such as online education, video, gaming, and connected cars.\\n----   Technology\\nShenzhen Bao\\'an District, the \"Internet\" City in Shenzhen, has established a 6G research and development base, and has a goal of achieving key technologies and product demonstrations by 2035. It will cooperate with various fields in the \"Belt and Road\" to build \"six high and one high\" research and development base.  \\n---- technology\\n\\nThe New York Stock Exchange (NYSE) closed at $ 10,930.44, an increase of 1.1% over the previous close, and the DJIA closed at 35582.84, an increase of 0.9% over the previous close.\\n---- Finance\\n\\nThe 5G commercial terminal industry, which includes mobile phones, laptops, set-top boxes and terminals for home networks, was the first to achieve annual sales of more than 100 million units in 2021.  \\n---- Technology\\n\\n\\n<|end_of_text|>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d289b58-bd66-4e38-aadc-4cac13a3cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Bitte vervollständige die Sentiments (Positiv, Neutral, Negativ):\n",
    "\n",
    "Schokolade kann Glücksgefühle hervorrufen. -> Positiv\n",
    "\n",
    "Eine Frau wurde von einem Auto überfahren. -> Negativ\n",
    "\n",
    "Ein Mann hat 10.000 Euro im Lotto gewonnen. -> Positiv\n",
    "\n",
    "Das Wetter ist heute genau so wie es gestern war. -> Neutral\n",
    "\n",
    "Ein Angestellter wurde befördert. -> \n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Circulation revenue has increased by 5% in Finland. --> Positive\n",
    "\n",
    "Panostaja did not disclose the purchase price. --> Neural\n",
    "\n",
    "Paying off the national debt will be extremely painful. --> Negative\n",
    "\n",
    "The company anticipated its operating profit to improve. --> \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
