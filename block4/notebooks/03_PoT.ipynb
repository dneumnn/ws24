{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bfa2d1-87ef-4873-a951-17ea825f966d",
   "metadata": {},
   "source": [
    "# Program of Thoughts \n",
    "\n",
    "PoT prompting has the LLM generate reasoning steps as programming language statements, \n",
    "which are then executed by an external interpreter like Python.\n",
    "\n",
    "While Chain-of-Thought uses LLMs for both reasoning and computation, PoT uses LLMs only for reasoning, but instead of using plain text for computations, it leverages code.\n",
    "\n",
    "\n",
    "- <https://medium.com/ai-advances/next-generation-in-chain-of-thought-program-of-thoughts-5c6ca75ee4fa>\n",
    "- <https://github.com/TIGER-AI-Lab/Program-of-Thoughts>\n",
    "- <https://arxiv.org/pdf/2211.12588>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3358eb-998f-4bf4-b2d4-5b5646894405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5db7f43-780a-450f-a654-965a75773f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_prompt = open(\"./pot_prompt.txt\", \"r\").read()\n",
    "pot_choices_prompt = open(\"./pot_choices_prompt.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbeafc15-8bd7-42f4-8d28-debf6def0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "def create_reader_request(example: Dict[str, Any]) -> str:\n",
    "    string =  f'# Question: {example[\"question\"]}\\n'\n",
    "    string += f'# Answer option: {example[\"options\"]}'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ea0b36-17b7-4e06-9dda-7ddec1a81378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "{'question': 'A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes for the angle of elevation to change from 45° to 60°. After how much more time will this car reach the base of the tower?', 'options': ['A)5(√3 + 1)', 'B)6(√3 + √2)', 'C)7(√3 – 1)', 'D)8(√3 – 2)', 'E)None of these'], 'rationale': 'Explanation :\\nLet the height of the building be h. Initially, he was at an angle of 450. tan 45 = h/distance between car and tower. h = distance between car and tower (since tan 45 = 1).\\nNow, after 10 minutes, it travelled a certain distance, and angle changed to 600.\\ntan 60 = h/x x = h/√3\\nSo, in 10 minutes, it has travelled a distance of h – x = h - h/√3.\\n10 minutes = h *( 1 – 1√3)\\nh can be travelled in 10 / (1 – 1√3).\\nTo travel a distance of x, which is h/√3, it takes :\\nh = 10 / (1 – 1/√3)\\nh / √3 = 10/ √3 * (1 – 1/√3). Multiply numerator and denominator by 1 + √3 ( conjugate of 1 - √3). We get, x = h/√3 = 10 (1 + √3) / 2 = 5* (1 + √3)\\nSo, it takes 5(1 + √3) minutes to reach the base of the tower.\\nAnswer : A', 'correct': 'A'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = open(\"./data/aqua_test.jsonl\", \"r\").read().strip().split(\"\\n\")\n",
    "examples = [json.loads(item) for i, item in enumerate(data)]\n",
    "print(len(examples))\n",
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36739b0e-c663-4fa1-81d8-84423ca63c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Greedy = just one run\n",
    "example = examples[0]\n",
    "\n",
    "messages = [{\"role\":\"user\", \"content\": pot_prompt + \"\\n\" + create_reader_request(example)}]\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model='llama3.2:latest', #'code-davinci-002'\n",
    "    messages=messages,\n",
    "    #max_tokens=256,\n",
    "    temperature=0.0,\n",
    "    top_p=1,\n",
    "    n=1,\n",
    "    #stop=['\\n\\n'],\n",
    "    logprobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed2220ed-08a6-4680-904e-805ee4d7e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Python code that solves all the given questions and stores the results in variables named `ans`:\n",
      "\n",
      "```python\n",
      "from sympy import Symbol, simplify, solve_it\n",
      "\n",
      "# Question: In a flight of 600 km, an aircraft was slowed down due to bad weather. Its average speed for the trip was reduced by 200 km/hr and the time of flight increased by 30 minutes.\n",
      "duration = Symbol('duration', positive=True)\n",
      "delay = 30 / 60\n",
      "total_disntace = 600\n",
      "original_speed = total_disntace / duration\n",
      "reduced_speed = total_disntace / (duration + delay)\n",
      "solution = solve_it(original_speed - reduced_speed - 200, duration)\n",
      "ans = solution[duration]\n",
      "\n",
      "# Question: M men agree to purchase a gift for Rs. D. If 3 men drop out how much more will each have to contribute towards the purchase of the gift?\n",
      "M = Symbol('M')\n",
      "D = Symbol('D')\n",
      "cost_before_dropout = D / M\n",
      "cost_after_dropout = D / (M - 3)\n",
      "ans=simplify(cost_after_dropout - cost_before_dropout)\n",
      "\n",
      "# Question: A sum of money at simple interest amounts to Rs. 815 in 3 years and to Rs. 854 in 4 years. The sum is:\n",
      "deposit = Symbol('deposit', positive=True)\n",
      "interest = Symbol('interest', positive=True)\n",
      "money_in_3_years = deposit + 3 * interest\n",
      "money_in_4_years = deposit + 4 * interest\n",
      "solution = solve_it([money_in_3_years - 815, money_in_4_years - 854], [deposit, interest])\n",
      "ans = solution[deposit]\n",
      "\n",
      "# Question: Find out which of the following values is the multiple of X, if it is divisible by 9 and 12?\n",
      "options = [36, 15, 17, 5, 7]\n",
      "for option in options:\n",
      "    if option % 9 == 0 and option % 12 == 0:\n",
      "        ans = option\n",
      "        break\n",
      "\n",
      "# Question: 35% of the employees of a company are men. 60% of the men in the company speak French and 40% of the employees of the company speak French. What is % of the women in the company who do not speak French?\n",
      "num_women = 65\n",
      "men_speaking_french = 0.6 * 35\n",
      "employees_speaking_french = 0.4 * 100\n",
      "women_speaking_french = employees_speaking_french - men_speaking_french\n",
      "women_not_speaking_french=num_women - women_speaking_french\n",
      "ans = women_not_speaking_french / num_women\n",
      "\n",
      "# Question: In one hour, a boat goes 11 km/hr along the stream and 5 km/hr against the stream. The speed of the boat in still water (in km/hr) is:\n",
      "boat_speed = Symbol('boat_speed', positive=True)\n",
      "stream_speed = Symbol('stream_speed', positive=True)\n",
      "along_stream_speed = 11\n",
      "against_stream_speed = 5\n",
      "solution = solve_it([boat_speed + stream_speed - along_stream_speed, boat_speed - stream_speed - against_stream_speed], [boat_speed, stream_speed])\n",
      "ans = (solution[boat_speed], solution[stream_speed])\n",
      "\n",
      "# Question: The area of a rectangle is 15 square centimeters and the perimeter is 16 centimeters. What are the dimensions of the rectangle?\n",
      "width = Symbol('width', positive=True)\n",
      "height = Symbol('height', positive=True)\n",
      "area = 15\n",
      "permimeter = 16\n",
      "solution = solve_it([width * height - area, 2 * (width + height) - permimeter], [width, height])\n",
      "ans = (solution[width], solution[height])\n",
      "\n",
      "# Question: A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes for the angle of elevation to change from 45° to 60°. After how much more time will this car reach the base of the tower?\n",
      "import math\n",
      "t = Symbol('t')\n",
      "angle1 = 45 * math.pi / 180\n",
      "angle2 = 60 * math.pi / 180\n",
      "distance = (10/60) * 11 * math.sin(angle1)\n",
      "time_to_reach_base = distance / 11\n",
      "tan_angle1 = math.tan(angle1)\n",
      "tan_angle2 = math.tan(angle2)\n",
      "tan_t = tan_angle2 / tan_angle1\n",
      "t_value = t * tan_t - 1/tan_angle1\n",
      "solution = solve_it(t_value, t)\n",
      "ans = solution[0]\n",
      "\n",
      "print(ans)\n",
      "```\n",
      "\n",
      "Note that for the last question, we used the `math` module to calculate the tangent of the angles and then solved for `t`.\n"
     ]
    }
   ],
   "source": [
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9cc329-f64e-4404-a713-0de6bafac595",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Self-consistency\n",
    "def prompt_for_choice(question: str, options: str, prediction: str) -> str:\n",
    "    prompt = f'{pot_choices_prompt}\\nQuestion: {question}\\nOptions: {options}\\nPrediction: {prediction}\\nClosest Option: '\n",
    "    messages = [{\"role\":\"user\", \"content\": prompt}]\n",
    "    \n",
    "    got_result = False\n",
    "    while not got_result:\n",
    "        try:\n",
    "            result = client.chat.completions.create(\n",
    "                model='llama3.2:latest', #'code-davinci-002'\n",
    "                messages=messages,\n",
    "                max_tokens=256,\n",
    "                temperature=0.0,\n",
    "                top_p=1,\n",
    "                n=20,\n",
    "                stop=['\\n'],\n",
    "                logprobs=1\n",
    "            )\n",
    "            got_result = True\n",
    "        except Exception:\n",
    "            sleep(3)\n",
    "\n",
    "    return result.choices[0].content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05296d1f-67e4-48ab-b369-a6a37e888df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### BACKUP ##########\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from time import sleep\n",
    "import sympy\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol\n",
    "import math\n",
    "import argparse\n",
    "from tool import simplify_ans, safe_execute\n",
    "from sympy import simplify\n",
    "from collections import Counter\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--key\", default='OPENAI_KEY', type=str)\n",
    "parser.add_argument(\"--start\", default=0, type=int)\n",
    "parser.add_argument(\"--end\", default=-1, type=int)\n",
    "parser.add_argument(\"--greedy\", default=False, action='store_true')\n",
    "parser.add_argument(\"--dry_run\", default=False, action='store_true')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.start = 0\n",
    "args.end = 1\n",
    "args.greedy = False\n",
    "args.dry_run = False\n",
    "\n",
    "def parse_api_result(result):\n",
    "    to_return = []\n",
    "    for idx, g in enumerate(result['choices']):\n",
    "        text = g['text']\n",
    "        logprob = sum(g['logprobs']['token_logprobs'])\n",
    "        to_return.append((text, logprob))\n",
    "    to_return = sorted(to_return, key=lambda tup: tup[1], reverse=True)\n",
    "    to_return = [r[0] for r in to_return]\n",
    "    return to_return\n",
    "\n",
    "def safe_execute(code_string: str, keys=None):\n",
    "    def execute(x):\n",
    "        try:\n",
    "            exec(x)\n",
    "            locals_ = locals()\n",
    "            if keys is None:\n",
    "                return locals_.get('ans', None)\n",
    "            else:\n",
    "                return [locals_.get(k, None) for k in keys]\n",
    "        except Exception:\n",
    "            return None\n",
    "    try:\n",
    "        ans = func_timeout.func_timeout(5, execute, args=(code_string,))\n",
    "    except func_timeout.FunctionTimedOut:\n",
    "        ans = None\n",
    "\n",
    "    return ans\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    aqua_test = []\n",
    "    with open('data/aqua_test.jsonl') as f:\n",
    "        for line in f:\n",
    "            tmp = json.loads(line)\n",
    "            aqua_test.append(tmp)\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "    correct, wrong = 0, 0\n",
    "    aqua_test = aqua_test[args.start:args.end]\n",
    "    if args.greedy:\n",
    "        filename = f'outputs/aqua_s{args.start}_e{args.end}_{dt_string}.jsonl'\n",
    "    else:\n",
    "        filename = f'outputs/aqua_sc_s{args.start}_e{args.end}_{dt_string}.jsonl'\n",
    "        \n",
    "    writer = open(filename, 'w')\n",
    "    writer.write(json.dumps({'demonstration': pot_prompt}) + '\\n')\n",
    "    for example in tqdm(aqua_test):\n",
    "        full_prompt = pot_prompt + \"\\n\"\n",
    "        full_prompt += create_reader_request(example)\n",
    "        if args.dry_run:\n",
    "            print(full_prompt)\n",
    "            print('=======================')\n",
    "            continue\n",
    "\n",
    "        if args.greedy:\n",
    "            # greedy decoding\n",
    "            got_result = False\n",
    "            while not got_result:\n",
    "                try:\n",
    "                    result = openai.Completion.create(\n",
    "                        engine='code-davinci-002',\n",
    "                        prompt=full_prompt,\n",
    "                        api_key=os.getenv(args.key),\n",
    "                        max_tokens=256,\n",
    "                        temperature=0.0,\n",
    "                        top_p=1,\n",
    "                        n=1,\n",
    "                        stop=['\\n\\n'],\n",
    "                        logprobs=1\n",
    "                    )\n",
    "                    got_result = True\n",
    "                except Exception:\n",
    "                    sleep(3)\n",
    "        else:\n",
    "            # self-consistency decoding\n",
    "            got_result = False\n",
    "            while not got_result:\n",
    "                try:\n",
    "                    result = openai.Completion.create(\n",
    "                        engine='code-davinci-002',\n",
    "                        prompt=full_prompt,\n",
    "                        api_key=os.getenv(args.key),\n",
    "                        max_tokens=256,\n",
    "                        temperature=0.3,\n",
    "                        top_p=1,\n",
    "                        n=30,\n",
    "                        stop=['\\n\\n'],\n",
    "                        logprobs=1\n",
    "                    )\n",
    "                    got_result = True\n",
    "                except Exception as e:\n",
    "                    sleep(3)\n",
    "            \n",
    "        # self-consistency decoding or greedy decoding.\n",
    "        result_counter = Counter()\n",
    "        codes = parse_api_result(result)\n",
    "        for r in codes:\n",
    "            ans = safe_execute(r)\n",
    "            pred = simplify_ans(ans)\n",
    "            if pred is not None:\n",
    "                result_counter.update([pred])\n",
    "        print(result_counter)\n",
    "\n",
    "        if len(result_counter) > 0:\n",
    "            prediction = result_counter.most_common(1)[0][0]        \n",
    "        else:\n",
    "            prediction = None\n",
    "\n",
    "        if prediction is None:\n",
    "            chosen_option = 'A'\n",
    "        else:\n",
    "            chosen_option = prompt_for_choice(\n",
    "                example['question'], example['options'], prediction)\n",
    "\n",
    "        if chosen_option == example['correct']:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "        tmp = {'question': example['question'],\n",
    "               'generated': codes,\n",
    "               'generated_prediction': str(prediction),\n",
    "               'options': example['options'],\n",
    "               'answer': example['correct'],\n",
    "               'prediction': chosen_option}\n",
    "\n",
    "        writer.write(json.dumps(tmp) + '\\n')\n",
    "\n",
    "    writer.close()\n",
    "    print()\n",
    "    print(correct / (correct + wrong))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
