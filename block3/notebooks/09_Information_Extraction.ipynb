{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cca52d-7e51-480f-805d-8d2fbee75e33",
   "metadata": {},
   "source": [
    "# WS24 - Intelligente Informationssysteme\n",
    "\n",
    "## Block 3: Retrieval Augmented Generation\n",
    "\n",
    "**Part 9: Advanced Information Extraction**\n",
    "\n",
    "1. Concept Extraction with Prompting\n",
    "2. Named Entity Recognition with GliNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc133f6-1e14-4985-816e-91d3f8c53a7c",
   "metadata": {},
   "source": [
    "## Concept Extraction with Prompting\n",
    "\n",
    "Extract Concepts, Entities and Relations out of text and make a knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1543988-261c-4f08-bea0-59ae3583202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data: each youtube video transcript is one document and should be handeled and chunked with llama_index\n",
    "import os\n",
    "\n",
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Path to data\n",
    "base_path = f\".{os.sep}data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c59e4-ea53-4b97-b7ca-cded72fea371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import json\n",
    "\n",
    "def _load_text(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def _load_metadata(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        metadata = json.loads(f.read())\n",
    "    return metadata\n",
    "\n",
    "def chunker(text:str, metadata={}, chunk_size=200) -> Tuple[Document, List[BaseNode]]:  \n",
    "    document = Document(text=text, metadata=metadata)\n",
    "    splitter = SentenceSplitter(\n",
    "        chunk_size=chunk_size,     # number of words\n",
    "        chunk_overlap=20,\n",
    "        #paragraph_separator = \"\\n\\n\\n\" not used \n",
    "    )\n",
    "    nodes = splitter.get_nodes_from_documents([document])\n",
    "    return (document, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3d795-3ccc-4c5a-9cc7-741fc58902aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = _load_text(file_path=f\"{base_path}/alice.txt\")\n",
    "document, nodes = chunker(text=text, metadata={}, chunk_size=200) # chunk size includes metadata size\n",
    "\n",
    "print(f\"There are {len(nodes)} nodes\")\n",
    "print(nodes[0].text, nodes[0].metadata)\n",
    "print(\"=\"*80)\n",
    "print(nodes[1].text, nodes[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c595a52-155d-45bd-97d9-94b3337c270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = [\"object\", \"entity\", \"location\", \"person\", \"concept\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7a074-3379-4273-9b19-330c54551d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = (\n",
    "    \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "    \"You are provided with a context chunk (delimited by ```). Your task is to extract the ontology \"\n",
    "    \"of terms mentioned in the given context. These terms should represent the key concepts as per the context. \\n\"\n",
    "    \"Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\\n\"\n",
    "        f\"\\tTerms may include {', '.join(TERMS)}, etc.\\n\"\n",
    "        \"\\tTerms should be as atomistic as possible\\n\\n\"\n",
    "    \"Thought 2: Think about how these terms can have one on one relation with other terms.\\n\"\n",
    "        \"\\tTerms that are mentioned in the same sentence or the same paragraph are typically related to each other.\\n\"\n",
    "        \"\\tTerms can be related to many other terms\\n\\n\"\n",
    "    \"Thought 3: Find out the relation between each such related pair of terms. \\n\\n\"\n",
    "    \"Format your output as a list of json. \\n\"\n",
    "    \"Each element of the list contains a pair of terms and the relation between them, like the follwing: \\n\"\n",
    "    \"```json\"\n",
    "    \"[\\n\"\n",
    "    \"   {\\n\"\n",
    "    '       \"node_1\": \"A concept from extracted ontology\",\\n'\n",
    "    '       \"node_2\": \"A related concept from extracted ontology\",\\n'\n",
    "    '       \"edge\": \"relationship between the two concepts, node_1 and node_2 explained in one verb or phrease\"\\n'\n",
    "    \"   }, {...}\\n\"\n",
    "    \"]\"\n",
    "    \"```\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ef8ba-9b36-4f8b-baf7-3db94785b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(text) -> list:\n",
    "    result = []\n",
    "    start = text.find(\"[\")\n",
    "    stop =  text.find(\"]\")\n",
    "    if start > 0 and stop > 0 and stop > start:\n",
    "        text = text[start:stop+1]\n",
    "    try:\n",
    "        result = json.loads(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bdaad-f255-4d41-a2fe-7b60e259309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '0123[{\"id\":5667, \"name\":\"Klaus\"}]9'\n",
    "result = clean_output(text)\n",
    "print(type(result),\":\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1a0bb-a77a-4a29-9866-d5005bc75212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes_edges(results:list) -> list:\n",
    "    formatted_results = []\n",
    "    for _dict in results:\n",
    "        try:\n",
    "            node_1 = _dict.get(\"node_1\",\"\").strip().lower()\n",
    "            node_2 = _dict.get(\"node_2\",\"\").strip().lower()\n",
    "            edge = _dict.get(\"edge\",\"unknown\").strip().lower()\n",
    "            if len(node_1) > 0 and len(node_2) > 0:\n",
    "                formatted_results.append((node_1, node_2, edge))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return formatted_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09f86d-e298-4e45-9767-ba5e2483d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i, node.node_id, end=\"\")\n",
    "    if 'graph_structure' in node.metadata:\n",
    "        graph_structure = node.metadata['graph_structure']\n",
    "    else:\n",
    "        messages = [{'role': 'system', 'content': SYS_PROMPT},\n",
    "                    {'role': 'user', 'content': f\"context: ```{node.text}``` \\n\\n output: \"}]\n",
    "        response = ollama.chat(model='llama3.2:latest', messages=messages)\n",
    "        results = clean_output(response.message.content)\n",
    "        graph_structure = extract_nodes_edges(results)\n",
    "        if len(graph_structure) == 0: #do a retry\n",
    "            print(\" retry\", end=\"\")\n",
    "            response = ollama.chat(model='llama3.2:latest', messages=messages)\n",
    "            results = clean_output(response.message.content)\n",
    "            graph_structure = extract_nodes_edges(results)\n",
    "        node.metadata = {\"graph_structure\": graph_structure}\n",
    "    #print(\"\\n\",graph_structure)\n",
    "    #print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70574a30-9bdf-42d5-afc2-709006d62853",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### save the data to disk #####\n",
    "#_json = {\"document\": document.to_dict(),\n",
    "#         \"node\": [node.to_dict() for node in nodes]}\n",
    "#with open(f\"{base_path}/alice.json\", \"w\") as f:\n",
    "#    f.write(json.dumps(_json, indent=3))\n",
    "\n",
    "###### just persist the nodes #######\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "docstore.persist(persist_path = f\"{base_path}/alice_nodes.bin\")\n",
    "\n",
    "###### load the data from disk #####\n",
    "new_docstore = SimpleDocumentStore.from_persist_path(persist_path = f\"{base_path}/alice_nodes.bin\")\n",
    "ref_doc_infos = new_docstore.get_all_ref_doc_info() # dictionary of RefDocInfo objects containing node_ids\n",
    "ref_doc_info = list(ref_doc_infos.values())[0]\n",
    "nodes = new_docstore.get_nodes(ref_doc_info.node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765aadc7-11fc-4713-aab2-7ef4c32cba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild a graph based on networkx\n",
    "import networkx as nx\n",
    "M = nx.MultiGraph() # Lets start with an undirected graph\n",
    "G = nx.Graph() # contextual proximity graph\n",
    "THRESHOLD = 2\n",
    "\n",
    "all_nodes = set()\n",
    "doc_nodes_dict = {}\n",
    "for node in nodes:\n",
    "    doc_nodes_dict[node.node_id] = []\n",
    "    all_edges_per_node = {}\n",
    "    for (source, target, edge) in node.metadata.get(\"graph_structure\", []):\n",
    "        all_nodes.add(source), all_nodes.add(target)\n",
    "        if (source, target, edge) not in all_edges_per_node:\n",
    "            all_edges_per_node[(source, target, edge)] = 0\n",
    "        all_edges_per_node[(source, target, edge)] += 1\n",
    "        doc_nodes_dict[node.node_id].append(source)\n",
    "        doc_nodes_dict[node.node_id].append(target)\n",
    "    \n",
    "    # add edges:\n",
    "    for (source, target, edge) in all_edges_per_node:\n",
    "        weight = all_edges_per_node[(source, target, edge)]\n",
    "        M.add_edge(source, target, relation=edge, title=edge, node_id=node.node_id, weight=weight)\n",
    "                \n",
    "    # add contextual proximity: nodes (source or target) in same text chunk\n",
    "    contextual_proximity_adjacency = {}\n",
    "    for source in doc_nodes_dict[node.node_id]:\n",
    "        for target in doc_nodes_dict[node.node_id]:\n",
    "            key = (source, target)\n",
    "            if key not in contextual_proximity_adjacency:\n",
    "                contextual_proximity_adjacency[key] = 0\n",
    "            contextual_proximity_adjacency[key] += 1\n",
    "    for (source, target) in contextual_proximity_adjacency:\n",
    "        weight = contextual_proximity_adjacency[(source, target)]\n",
    "        if source != target and weight > THRESHOLD:\n",
    "            G.add_edge(source, target, relation=\"contextual proximity\", title=\"contextual proximity\",\n",
    "                       node_id=node.node_id, weight=weight)\n",
    "            M.add_edge(source, target, relation=\"contextual proximity\", title=\"contextual proximity\",\n",
    "                       node_id=node.node_id, weight=weight)\n",
    "print(M)\n",
    "print(G)\n",
    "print(f\"There are {len(all_nodes)} unique node candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7650e-6704-44cf-9a0a-c7ffa15b8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Girvan-Newman Community Detection Algorithm\n",
    "communities_generator = nx.community.girvan_newman(M)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66338cce-e31e-43da-8295-c2a09754ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for i,nodelist in enumerate(communities):\n",
    "    clusters[i] = nodelist\n",
    "\n",
    "graph_nodes = M.nodes()\n",
    "\n",
    "for i in clusters:\n",
    "    for node_id in clusters[i]:\n",
    "        M.nodes[node_id]['color'] = i\n",
    "        M.nodes[node_id]['group'] = i\n",
    "        M.nodes[node_id]['size'] = M.degree(node_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46215d5-56d4-460e-bd22-62653888f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3919c-187b-4df5-8e60-54e731ab849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    # bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    # font_color=\"#cccccc\",\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "net.from_nx(M)\n",
    "# net.repulsion(node_distance=150, spring_length=400)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "net.show(\"./index.html\", notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee3cdc-0ce4-4a25-b172-e00ed6351a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: save the graph into neoj4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df0e04-e3db-46fd-a763-e6826ca640c3",
   "metadata": {},
   "source": [
    "## Named Entity Recognition with GliNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd147d-6ebf-488c-b0b1-a55389793253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288362ea-f7ae-41e4-98a3-38172d51024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ec887-15bd-4657-bad6-bbf9de68b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "text = _load_text(file_path=f\"{base_path}/alice.txt\")\n",
    "\n",
    "(document, nodes) = chunker(text=text, metadata={}, chunk_size=200)\n",
    "\n",
    "labels = [\"object\", \"entity\", \"location\", \"person\", \"concept\", \"animal\"]\n",
    "\n",
    "entities_in_nodes = {}\n",
    "for i, node in enumerate(nodes):\n",
    "    \n",
    "    entities = model.predict_entities(node.text, labels)\n",
    "    \n",
    "    node.metadata['entities'] = []\n",
    "    for entity in entities:\n",
    "        name = str(entity[\"text\"]).lower()\n",
    "        entity[\"text\"] = name\n",
    "        label = entity[\"label\"]\n",
    "        node.metadata['entities'].append((name, label))\n",
    "        if name not in entities_in_nodes:\n",
    "            entities_in_nodes[name] = set()\n",
    "        entities_in_nodes[name].add(node.node_id)\n",
    "    print(node.metadata['entities'])\n",
    "    if i> 10: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3d6c5-6a9b-4c5d-9eb1-d2293d8de280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
