{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c581e-b952-4312-9e9c-271b1f950433",
   "metadata": {},
   "source": [
    "# WS24 - Intelligente Informationssysteme\n",
    "\n",
    "## Block 3: Retrieval Augmented Generation\n",
    "\n",
    "Build your first simple RAG with LangChain. We follow the LangChain Tutorial \"Build a Retrieval Augmented Generation (RAG) App\" found at <https://python.langchain.com/docs/tutorials/rag/>.\n",
    "\n",
    "**Part 2: Retrieve Knowledge from Vectorstore and Generate Answers**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375fdead-5171-4113-8225-2a0978a21b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x10c2ed510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Langchain\n",
    "# Vector stores are commonly used for retrieval, but there are other ways to do retrieval, too.\n",
    "# Retriever: An object that returns Documents given a text query\n",
    "# Open a vectore store as retriever\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma(persist_directory=\"vector_store\", collection_name=\"lils_blogs\", embedding_function=embeddings)\n",
    "\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21cc8ba-9d53-49c0-b4e9-23d128a905de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "question = \"What are the approaches to task decomposition?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d39e88-bc3e-4497-970d-c72a6e4cae0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d1b52f-93e5-4e27-a60c-ecb83feb27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat Models: Modern LLMs are typically accessed through a chat model interface \n",
    "# that takes a list of messages as input and returns a message as output.\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b671de3c-7b0c-46b2-b398-934aa394ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e2b0b0-e4e8-4cfe-b473-bd0abb2d45ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: What are the approaches to task decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process. \\nAnswer:\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = prompt_template.invoke(\n",
    "    {\"context\": retrieved_docs[0].page_content, \"question\": question}\n",
    ").to_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54afaed-c85c-4059-84c8-f608255c6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133450b8-da0d-4584-b3e5-0b7df4c19f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "Task decomposition approaches include Chain of Thought (CoT), which involves instructing a model to break down complex tasks into smaller, simpler steps by \"thinking step by step\". Another approach is not explicitly mentioned in the provided context. CoT has become a standard prompting technique for enhancing model performance on complex tasks.\n",
      "---------------\n",
      "id               : run-d4a4c5d9-5629-4ac6-b004-f28e4f1b3f9f-0\n",
      "additional_kwargs: {}\n",
      "response_metadata: {'model': 'llama3.2:latest', 'created_at': '2024-11-30T10:53:46.403054Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4912976792, 'load_duration': 822084875, 'prompt_eval_count': 214, 'prompt_eval_duration': 3249000000, 'eval_count': 62, 'eval_duration': 840000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}\n",
      "usage_metadata   : {'input_tokens': 214, 'output_tokens': 62, 'total_tokens': 276}\n"
     ]
    }
   ],
   "source": [
    "print(type(message))\n",
    "print(message.content)\n",
    "print(\"---------------\")\n",
    "print(\"id               :\", message.id)\n",
    "print(\"additional_kwargs:\", message.additional_kwargs)\n",
    "print(\"response_metadata:\", message.response_metadata)\n",
    "print(\"usage_metadata   :\", message.usage_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c888a0-d524-4c0a-b0bf-4cfd74a06e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
