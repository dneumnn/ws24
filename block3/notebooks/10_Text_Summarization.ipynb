{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cca52d-7e51-480f-805d-8d2fbee75e33",
   "metadata": {},
   "source": [
    "# WS24 - Intelligente Informationssysteme\n",
    "\n",
    "## Block 3: Retrieval Augmented Generation\n",
    "\n",
    "**Part 10: Text Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc133f6-1e14-4985-816e-91d3f8c53a7c",
   "metadata": {},
   "source": [
    "## Abstractive Text Summarization\n",
    "Abstractive summarization involves generating a concise summary that may contain words, phrases, or sentences not present in the source text. This approach relies on understand- ing the context and generating human-like language to convey the central ideas. Abstractive summarization methods often use advanced language models, such as Large Language Models (LLMs), to rewrite and rephrase content in a more concise form.\n",
    "\n",
    "## Extractive Text Summarization\n",
    "Extractive summarization, on the other hand, aims to select and extract the most important sentences or phrases directly from the source text to form the summary. It does not involve rephrasing or generating new sentences. Extractive summariza- tion methods use various techniques, such as sentence scoring and ranking, to identify and extract the most salient content.\n",
    "\n",
    "see: https://arxiv.org/pdf/2310.10449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1543988-261c-4f08-bea0-59ae3583202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data: each youtube video transcript is one document. We want a summarization of each docutment.\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Path to data\n",
    "base_path = f\".{os.sep}data{os.sep}vRTcE19M-KE\"\n",
    "with open(f\"{base_path}{os.sep}grammar_corrected_sentences.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    print(len(text))\n",
    "with open(f\"{base_path}{os.sep}video.json\", \"r\") as f:\n",
    "    video = json.loads(f.read())\n",
    "    description = video.get('description', \"\")\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b93b07-3c0e-4906-8cc9-c8544fd9f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we regenerate a meaningful transcription out of the grammar corrected transcription?\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7247d-9d69-42b6-ac4b-0bec545cf4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"As a professional summarizer, create a concise and comprehensive summary of the provided text, be it an article, post, conversation, or passage, while adhering to these guidelines:\n",
    "* Craft a summary that is detailed, thorough, in-depth, and complex, while maintaining clarity and conciseness.\n",
    "* Incorporate main ideas and essential information, eliminating extraneous language and focusing on critical aspects.\n",
    "* Rely strictly on the provided text, without including external information.\n",
    "* Format the summary in paragraph form for easy understanding.\n",
    "* Conclude your notes with [End of Notes] to indicate completion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306196bd-e83d-4dac-a454-4f171deafbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': SYS_PROMPT}, \n",
    "            {'role': 'user', 'content': f\"Please summarize the following: ```{text}``` \\n\\n output: \"}]\n",
    "response = ollama.chat(model='llama3.2:latest', messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cc7ed-b239-4df9-99e4-54abfa6270be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b154077-3168-488c-adad-2119e2e4d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to measure generated summaries?\n",
    "# Bilingual Evaluation Understudy (BLEU) Score, \n",
    "# Recall-Oriented Understudy for Gisting Evaluation (ROUGE) Score, \n",
    "# and Bidirectional Encoder Representations from Transformers (BERT) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3d561-2976-45ac-901e-e775e7b4a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "words = []\n",
    "for sentence in nltk.sent_tokenize(description):\n",
    "   words.extend(nltk.word_tokenize(sentence))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7adbc-d812-4d1c-b1e9-e3b100943f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': SYS_PROMPT}, \n",
    "            {'role': 'user', 'content': f\"Please summarize the following in less then {len(words)} words: ```{text}``` \\n\\n output: \"}]\n",
    "response = ollama.chat(model='llama3.2:latest', messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f5d0e-476d-4d74-8396-7085fcb77b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec2110-e0a2-4bf0-87e1-13140c1915a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': SYS_PROMPT},\n",
    "            {'role': 'user', 'content': f\"```{text}``` TL;DR:\\n\"}]\n",
    "response = ollama.chat(model='llama3.2:latest', messages=messages)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e64ec0-0dff-4c6c-9f53-b7f4dd2c139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fffa4-6bb2-4fe9-bab9-d71755150d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# who can we measure the generated summaries\n",
    "# Bilingual Evaluation Understudy (BLEU) Score, \n",
    "# Recall-Oriented Understudy for Gisting Evaluation (ROUGE) Score, and \n",
    "# Bidirectional Encoder Representations from Transformers (BERT) Score\n",
    "\n",
    "# Confidence Scores\n",
    "# seee: https://medium.com/@rakesharma21/confidence-scores-in-ai-summarization-an-insightful-approach-995603c72cab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d93a2d-a612-4fbf-b619-782f151761da",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Backup\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09813ec0-001f-48da-a1cc-f3cebd3c7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5effe78-df84-4b99-81bf-e544a0490686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
