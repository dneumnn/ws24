{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bd42e8-1846-48a3-84cd-97e35075da5f",
   "metadata": {},
   "source": [
    "# WS24 - Intelligente Informationssysteme\n",
    "\n",
    "## Block 3: Retrieval Augmented Generation\n",
    "\n",
    "**Part 5: Advanced Retrieval - Routing**\n",
    "\n",
    "1. Logical Datasource Routing\n",
    "2. Semantic Prompt Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055de8ed-7a7b-494e-a5d5-7585c4d1ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIRST: Initialize the VectorDB and LLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(persist_directory=\"vector_store\", collection_name=\"lils_blogs\", embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\") #, search_kwargs={\"k\": 2})\n",
    "\n",
    "## LLM with function calling ability\n",
    "llm = ChatOllama(model=\"llama3.2:latest\", temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ba0a671-0736-46ad-9181-8aa4b192b2fa",
   "metadata": {},
   "source": [
    "## 1. Logical Routing: Logical Datasource Routing\n",
    "\n",
    "Find the right datastore\n",
    "\n",
    "![Logical Routing](./media/LangChain_Logical_Routing.png \"Logical Routing\")\n",
    "\n",
    "\n",
    "see: \n",
    "- https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd8bf7e-cfb2-4708-9d9a-065e218043a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Detect the used programming language.\"\"\"\n",
    "\n",
    "    programming_language: Literal[\"python\", \"java\", \"golang\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question with some source code as an example identify the programming language.\",\n",
    "    )\n",
    "\n",
    "# \n",
    "# llm.with_structured_output(schema)\n",
    "# \n",
    "# The output schema can be passed in as:\n",
    "# - an OpenAI function/tool schema,\n",
    "# - a JSON Schema,\n",
    "# - a TypedDict class (support added in 0.2.26),\n",
    "# - or a Pydantic class. If ``schema`` is a Pydantic class then the model output will be a Pydantic instance of that class, \n",
    "#   and the model-generated fields will be validated by the Pydantic class. \n",
    "#\n",
    "# Otherwise the model output will be a dict and will not be validated.\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b04fa6-03cb-47cb-8d31-73aaed41f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt \n",
    "system = \"\"\"You are an expert in coding and programming in the languages java, python and golang. \n",
    "\n",
    "Based on the programming language the question is referring to, return the name of the programming language.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router \n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63da622-e607-4762-8791-cfc52d891b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke({\"question\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2fc144-d571-4e28-a3ed-c23db74989d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(programming_language='python')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50569fc-82ae-47c6-bcc6-3f9c1e265712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def integer_multiplication(x: int, y: int) -> int:\n",
      "    return x * y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def integer_multiplication(x: int, y: int) -> int:\n",
    "    return x * y\n",
    "\n",
    "code_lines = inspect.getsource(integer_multiplication)\n",
    "print(code_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516c7d5e-2bd1-427d-9898-9bb96ef74606",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\" Describe the the following method:\n",
    "\n",
    "{code_lines}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke(question.format(code_lines=code_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4012184a-4c60-4bb3-ac17-452179b22878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(programming_language='python')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9a135c-8e3f-4781-a33b-6395591b4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\" What is wrong with this code example:\n",
    "\n",
    "public class Main {\n",
    "  public class void main(String[] args) {\n",
    "    System.out.println(max(5, 10));  \n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "result = router.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd1fe63-0749-4523-8abd-195a16a7d7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(programming_language='java')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b79d2-c1a1-43ee-b57d-ea6b61488495",
   "metadata": {},
   "source": [
    "## 1. Semantic Routing: Prompt Selection\n",
    "\n",
    "Choose the right prompt\n",
    "\n",
    "![Semantic Routing](./media/LangChain_Semantic_Routing.png \"Semantic Routing\")\n",
    "\n",
    "\n",
    "see: \n",
    "- https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9ab7c6-846e-46da-ab9b-bab7a2df255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Two prompts\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a restaurant with a local menu. You serve local specialities.\n",
    "Special of today is:\n",
    "- Flädlesuppe\n",
    "- Rahmhackbraten mit Champigion, Spätzle und Salat\n",
    "- Sauerbraten\n",
    "\n",
    "You are great at answering questions about the special of the day. \\\n",
    "\n",
    "Here is a question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Embed prompts\n",
    "prompt_templates = [physics_template, math_template, restaurant_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Route question to prompt \n",
    "def prompt_router(input):\n",
    "    # Embed question\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # Chosen prompt \n",
    "    if most_similar == math_template:\n",
    "        print(\"Using MATH\")  \n",
    "    elif most_similar == physics_template:\n",
    "        print(\"Using PHYSICS\") \n",
    "    else:\n",
    "        print(\"Beeing a RESTAURANT\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "286bc266-e324-4fde-9ddd-5cd96fd7ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MATH\n",
      "A matrix! A fundamental concept in linear algebra and mathematics.\n",
      "\n",
      "To break it down, let's start with the basics:\n",
      "\n",
      "**Definition:** A matrix is a rectangular array of numbers, symbols, or expressions, arranged in rows and columns. It's often represented as a set of ordered pairs (a, b), where 'a' represents an element in the first row and column, 'b' represents an element in the second row and column, and so on.\n",
      "\n",
      "**Components:**\n",
      "\n",
      "1. **Rows:** A matrix has multiple rows, which are horizontal lines that contain elements.\n",
      "2. **Columns:** A matrix also has multiple columns, which are vertical lines that contain elements.\n",
      "3. **Elements:** Each element is a single number or symbol within the matrix.\n",
      "\n",
      "**Types of Matrices:**\n",
      "\n",
      "1. **Square Matrix:** A square matrix has the same number of rows and columns.\n",
      "2. **Rectangular Matrix:** A rectangular matrix has more rows than columns (or vice versa).\n",
      "3. **Diagonal Matrix:** A diagonal matrix has non-zero elements only on its main diagonal.\n",
      "\n",
      "**Operations with Matrices:**\n",
      "\n",
      "1. **Addition:** Matrices can be added element-wise, just like numbers.\n",
      "2. **Multiplication:** Matrices can be multiplied using various methods, such as:\n",
      " * **Matrix Multiplication:** When the number of columns in the first matrix matches the number of rows in the second matrix.\n",
      " * **Outer Product:** A special type of multiplication that creates a new matrix.\n",
      "\n",
      "**Properties:**\n",
      "\n",
      "1. **Determinant:** The determinant is a scalar value that can be calculated from a square matrix, which determines its invertibility.\n",
      "2. **Inverse:** A matrix has an inverse if and only if it's invertible (i.e., its determinant is non-zero).\n",
      "\n",
      "Now, let's put these components together to answer the broader question:\n",
      "\n",
      "A matrix is a fundamental concept in mathematics that represents a rectangular array of numbers or symbols, with rows and columns, elements, and various operations like addition and multiplication. Matrices can be classified into different types (square, rectangular, diagonal), and they have properties like determinants and inverses.\n",
      "\n",
      "How's that? Did I help clarify what a matrix is for you?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's a matrix\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434f10f2-63a7-4ca1-bfe2-1b44693d7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "A black hole! One of the most fascinating and mysterious objects in the universe.\n",
      "\n",
      "A black hole is essentially a region in space where the gravitational pull is so strong that nothing, including light, can escape. It's formed when a massive star collapses in on itself and its gravity becomes so strong that it warps the fabric of spacetime around it.\n",
      "\n",
      "Imagine spacetime as a trampoline: if you place a heavy object, like a bowling ball, on the trampoline, it will warp and curve, creating a depression. Now imagine taking that bowling ball and making it infinitely dense and heavy – that's roughly what happens in a black hole. The gravity is so strong that it creates a boundary called the event horizon, which marks the point of no return.\n",
      "\n",
      "Once something crosses the event horizon, it's trapped by the black hole's gravity and can't escape. That's why black holes are invisible to us, as not even light can escape to reach our eyes.\n",
      "\n",
      "Black holes come in different sizes, ranging from small, stellar-mass black holes formed from the collapse of individual stars, to supermassive black holes found at the centers of galaxies, with masses millions or even billions of times that of our sun!\n",
      "\n",
      "That's a brief introduction to black holes. Do you have any follow-up questions?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's a black hole\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b5cef6-28a8-421e-a603-b659bbdee4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeing a RESTAURANT\n",
      "Rahmkuchen! That's a classic local specialty from our region. Rahmkuchen is a traditional German bread that's made with fermented rye flour, water, salt, and sometimes caraway seeds or other spices. The fermentation process gives it a distinctive sour taste and a dense, chewy texture.\n",
      "\n",
      "In our restaurant, we serve Rahmkuchen as a side dish to many of our local specialties, including the Rahmhackbraten you saw on our menu today. It's often served warm, sliced into thick pieces, and is a perfect accompaniment to the rich flavors of the braised beef and vegetables in the Rahmhackbraten.\n",
      "\n",
      "Would you like to try some Rahmkuchen with your meal today?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's Rahmkuchen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83ba63-d697-4a9d-9aae-b457a9b7d9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
